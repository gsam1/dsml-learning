{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10 â€” MORE NLP AND COLUMNAR DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Course Notebook on Github](https://github.com/fastai/fastai/blob/master/courses/ml1/lesson5-nlp.ipynb)\n",
    "\n",
    "### Notes\n",
    "My goal is not to copy what it is taught in the course and in the notebook. Its just various notes and trying things for my own.\n",
    "Extrapolation in the previous notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture Personal Notes\n",
    "\n",
    "1. Learning Rate Annealing - Decrease the lr to adjust to increase the accuracy.\n",
    "2. Regularization - l2 \n",
    "    * loss = Sum(y_hat - y)^2 / n  - standard loss function\n",
    "    * l2 - alpha * w^2 (sqrt of sums) -> alpha ~ 1e-666\n",
    "    * l1 - absolute value of the wieghts\n",
    "    * gradient of loss = 2aw -> weight decay\n",
    "    * Weight decay - make function behave better\n",
    "    * Training Loss > Validation Loss - underfit - no regularization\n",
    "    * Training Loss < Validation Loss - overfit - try regularization\n",
    "    * Massivly Overparametirze the model and add regularization\n",
    "3. Finally NLP\n",
    "    * Linear model is close to SOA\n",
    "    * Create a vocabulary (features) - how many good/bad words appear.\n",
    "        * BOW model - what frequency of the words appear.\n",
    "        * Number of unique words.\n",
    "        * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "# from fastai.nlp import * \n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'datasets/aclImdb/'\n",
    "names  = ['neg', 'pos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0_9.txt\n",
      "10000_8.txt\n",
      "10001_10.txt\n",
      "10002_7.txt\n",
      "10003_8.txt\n",
      "10004_8.txt\n",
      "10005_7.txt\n",
      "10006_7.txt\n",
      "10007_7.txt\n",
      "10008_7.txt\n",
      "ls: write error: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "%ls {PATH}train/pos | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
